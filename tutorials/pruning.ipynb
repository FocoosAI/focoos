{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655e87e0",
   "metadata": {},
   "source": [
    "# üî• How to use Focoos Pruning functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc183a",
   "metadata": {},
   "source": [
    "## üêç Setup Focoos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'focoos @ git+https://github.com/FocoosAI/focoos.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7144bd65",
   "metadata": {},
   "source": [
    "# üé® What is Pruning and how to prune\n",
    "\n",
    "**Pruning** is a technique used to reduce the size and complexity of a neural network by removing less important parameters.\n",
    "\n",
    "Pruning can target:\n",
    "\n",
    "* **Weights:** Removing individual connections.\n",
    "* **Neurons or filters:** Removing entire channels or feature maps (structured pruning).\n",
    "\n",
    "Unlike the built-in `torch.nn.utils.prune module`, which only masks weights or entire layers (keeping their original size and structure), the `torch-pruning` library goes further. It actually removes the pruned weights or filters from the model architecture.\n",
    "\n",
    "It can updates:\n",
    "\n",
    "* The **layer dimensions**, and\n",
    "* The **dependencies** between layers (so that input/output shapes remain consistent).\n",
    "\n",
    "Focoos pruning functionality is **built on top of the `torch-pruning` library**, inheriting its core functionality and dependency graph logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c4149",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Focoos Pruning Setup\n",
    "\n",
    "You can define which layers to prune in a specific model by providing their names as strings in a list. There are two main ways to do this:\n",
    "\n",
    "- Manually create the list of layer names you wish to prune.\n",
    "\n",
    "- Load a predefined list from `prunable_layers.json`, which contains recommended prunable layers for various model architectures.\n",
    "\n",
    "For the selected layers, the pruning intensity is controlled using the `prune_ratio` parameter, which defines the fraction of channels to remove from each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0a10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import DatasetLayout, Task\n",
    "\n",
    "TASK = Task.DETECTION\n",
    "DATASET_NAME = \"coco_2017_det\"\n",
    "DATASET_LAYOUT = DatasetLayout.CATALOG\n",
    "DEVICE = \"cpu\"\n",
    "RESOLUTION = 640\n",
    "BENCHMARK_ITERATIONS = 200\n",
    "VERBOSE = False\n",
    "DO_EVAL = True  # compute or not eval metrics\n",
    "\n",
    "OUTPUT_FOLDER = \"pruning_outputs\"  # folder to save the pruning results and pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from focoos import PACKAGE_DIR\n",
    "\n",
    "layers_to_prune = json.load(open(os.path.join(PACKAGE_DIR, \"pruning\", \"prunable_layers.json\")))\n",
    "\n",
    "MODEL_NAME = \"fai-detr-m-coco\"\n",
    "PRUNE_RATIO = 0.3\n",
    "LAYERS_TO_PRUNE = layers_to_prune[MODEL_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612a5432",
   "metadata": {},
   "source": [
    "# üöÄ Setup and run pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.pruning.focoos_pruning import FocoosPruning\n",
    "\n",
    "pruning_pipeline = FocoosPruning(\n",
    "    task=TASK,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    dataset_layout=DATASET_LAYOUT,\n",
    "    device=DEVICE,\n",
    "    verbose=VERBOSE,\n",
    "    do_eval=DO_EVAL,\n",
    "    root_dir=OUTPUT_FOLDER,\n",
    "    model_name=MODEL_NAME,\n",
    "    resolution=RESOLUTION,\n",
    "    prune_ratio=PRUNE_RATIO,\n",
    "    benchmark_iterations=BENCHMARK_ITERATIONS,\n",
    "    layers_to_prune=LAYERS_TO_PRUNE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e613fd6",
   "metadata": {},
   "source": [
    "The Focoos pruning pipeline outputs a summary table that compares key metrics of the pruned model against the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e95208",
   "metadata": {},
   "source": [
    "## üîÅ Iterative Pruning and Re-training (beta)\n",
    "\n",
    "The best practice is to prune **iteratively**, not all at once:\n",
    "\n",
    "1. Prune a small percentage of weights or filters.\n",
    "2. Retrain (or fine-tune) the model to recover accuracy.\n",
    "3. Repeat until you reach the desired compression level.\n",
    "\n",
    "This **gradual approach** preserves performance much better than aggressive one-shot pruning.\n",
    "\n",
    "üí° Tip: Not all layers contribute equally to model efficiency or accuracy.\n",
    "It‚Äôs often best to selectively prune layers that are over-parameterized or less critical to the model‚Äôs performance. Pruning all layers uniformly can cause unnecessary accuracy degradation. Selective pruning enables smarter and more effective compression.\n",
    "At each pruning iteration, carefully evaluate which layers to prune, and avoid pruning the exact same layers in every cycle to maintain an adaptive optimization process.\n",
    "\n",
    "‚ö†Ô∏è Work in progress: Currently, the process supports only a single automated pruning iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305f37a8",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Iterative Pruning-Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bceb373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from focoos import PACKAGE_DIR\n",
    "\n",
    "layers_to_prune = json.load(open(os.path.join(PACKAGE_DIR, \"pruning\", \"prunable_layers.json\")))\n",
    "\n",
    "TASK = Task.DETECTION\n",
    "DATASET_NAME = \"coco_2017_det\"\n",
    "DATASET_LAYOUT = DatasetLayout.CATALOG\n",
    "DEVICE = \"cpu\"\n",
    "RESOLUTION = 640\n",
    "BENCHMARK_ITERATIONS = 200\n",
    "VERBOSE = False  # print or not additional pruning information\n",
    "DO_EVAL = False  # compute or not eval metrics\n",
    "\n",
    "MODEL_NAME = \"fai-detr-m-coco\"\n",
    "OUTPUT_FOLDER = \"pruning_outputs-test\"\n",
    "\n",
    "PRUNE_RATIO = 0.5\n",
    "LAYERS_TO_PRUNE = layers_to_prune[MODEL_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import DatasetLayout, Task, TrainerArgs\n",
    "from focoos.data import AutoDataset, get_default_by_task\n",
    "from focoos.ports import DatasetSplitType\n",
    "from focoos.pruning.focoos_pruning import FocoosPruning\n",
    "\n",
    "pruning_pipeline = FocoosPruning(\n",
    "    task=TASK,\n",
    "    dataset_name=DATASET_NAME,\n",
    "    dataset_layout=DATASET_LAYOUT,\n",
    "    device=DEVICE,\n",
    "    verbose=VERBOSE,\n",
    "    do_eval=DO_EVAL,\n",
    "    root_dir=OUTPUT_FOLDER,\n",
    "    model_name=MODEL_NAME,\n",
    "    resolution=RESOLUTION,\n",
    "    prune_ratio=PRUNE_RATIO,\n",
    "    benchmark_iterations=BENCHMARK_ITERATIONS,\n",
    "    layers_to_prune=LAYERS_TO_PRUNE,\n",
    ")\n",
    "\n",
    "auto_dataset = AutoDataset(\n",
    "    dataset_name=\"coco_2017_det\",\n",
    "    task=Task.DETECTION,\n",
    "    layout=DatasetLayout.CATALOG,\n",
    ")\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(Task.DETECTION, resolution=RESOLUTION)\n",
    "\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "val_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08aa515",
   "metadata": {},
   "source": [
    "### üöÄ Run first iteration of Pruning-Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import ModelManager\n",
    "\n",
    "# 1st step: Pruning\n",
    "pruning_pipeline.run()\n",
    "output_directory = pruning_pipeline.output_directory\n",
    "\n",
    "# 2nd step: Training\n",
    "\n",
    "# Set pruning output directory in TrainerArgs\n",
    "assert output_directory is not None\n",
    "args = TrainerArgs(\n",
    "    run_name=f\"{MODEL_NAME}_{val_dataset.name}\",\n",
    "    batch_size=8,\n",
    "    max_iters=10_000,\n",
    "    eval_period=500,\n",
    "    learning_rate=0.0008,\n",
    "    device=DEVICE,\n",
    "    output_dir=output_directory,\n",
    ")\n",
    "\n",
    "# Training\n",
    "model = ModelManager.get(output_directory)\n",
    "model.train(args, train_dataset, val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
