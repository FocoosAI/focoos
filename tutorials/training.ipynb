{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßëüèΩ‚Äçüç≥ How to Train a Computer Vision Model with Focoos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêç Setup Focoos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "%pip install 'focoos @ git+https://github.com/FocoosAI/focoos.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Fine-tune a model in few steps\n",
    "\n",
    "This section covers the steps to create a model and train it using the focoos library. The following example demonstrates how to interact with the Focoos API to manage models, datasets, and training jobs.\n",
    "\n",
    "In this guide, we will perform the following steps:\n",
    "\n",
    "\n",
    "0. ‚òÅÔ∏è [Optional] Connect with Focoos Hub\n",
    "1. üéØ Select Pretrained Model\n",
    "2. üì¶ Load a dataset\n",
    "3. üèÉ‚Äç‚ôÇÔ∏è Train the model\n",
    "4. üß™ Test your model\n",
    "5. üì§ Export your model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è [Optional] Connect with FocoosHUB\n",
    "\n",
    "Focoos can be used without having an accont on the [Focoos Hub](app.focoos.ai). With it, you will unlock additional functionalities, as we will see below. If you have it, just connect to the HUB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from focoos.hub import FocoosHUB\n",
    "\n",
    "FOCOOS_API_KEY = os.getenv(\"FOCOOS_API_KEY\")  # write here your API key os set env variable FOCOOS_API_KEY\n",
    "hub = FocoosHUB(api_key=FOCOOS_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ List Pretrained Focoos Models with ModelRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_registry import ModelRegistry\n",
    "\n",
    "model_registry = ModelRegistry()\n",
    "\n",
    "for m in model_registry.list_models():\n",
    "    model_info = model_registry.get_model_info(m)\n",
    "    model_info.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model with ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_manager import ModelManager\n",
    "\n",
    "model_name = \"fai-detr-l-obj365\"\n",
    "model = ModelManager.get(model_name)\n",
    "model.model_info.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Download datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public toy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.hub.api_client import ApiClient\n",
    "from focoos.ports import DATASETS_DIR, DatasetLayout, Task\n",
    "\n",
    "ds_task = Task.DETECTION\n",
    "\n",
    "\n",
    "def get_dataset(task: Task):\n",
    "    if task == Task.SEMSEG:\n",
    "        ds_name = \"balloons-coco-sem.zip\"\n",
    "        layout = DatasetLayout.ROBOFLOW_SEG\n",
    "    elif task == Task.DETECTION:\n",
    "        ds_name = \"chess-coco-detection.zip\"\n",
    "        layout = DatasetLayout.ROBOFLOW_COCO\n",
    "    elif task == Task.INSTANCE_SEGMENTATION:\n",
    "        ds_name = \"fire-coco-instseg.zip\"\n",
    "        layout = DatasetLayout.ROBOFLOW_COCO\n",
    "    else:\n",
    "        raise ValueError(f\"Error: task {task} not supported\")\n",
    "    url = f\"https://public.focoos.ai/datasets/{ds_name}\"\n",
    "    api_client = ApiClient()\n",
    "    api_client.download_ext_file(url, DATASETS_DIR, skip_if_exists=True)\n",
    "    return ds_name, layout\n",
    "\n",
    "\n",
    "# Downlaod sample dataset\n",
    "ds_name, ds_layout = get_dataset(ds_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Datasets from focoos Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to download a dataset from the hub, you can use the hub to directly store it in your local environment.\n",
    "Check the reference of your dataset on the platform and use it in the following cell.\n",
    "In the next cell, we will download a dataset by reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_datasets = hub.list_remote_datasets()\n",
    "for dataset in hub_datasets:\n",
    "    print(dataset.name, dataset.ref)\n",
    "\n",
    "\n",
    "ref = None  # place here the ref of the dataset you want to download\n",
    "if ref is not None:\n",
    "    dataset = hub.get_remote_dataset(ref)\n",
    "    dataset_path = dataset.download_data()\n",
    "    ds_name = dataset_path\n",
    "    ds_layout = dataset.layout\n",
    "    ds_task = dataset.task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoDataset and Augmentation\n",
    "Now that we downloaded the dataset, we can magically ü™Ñ instanciate the dataset using the `AutoDataset` as will be used in the training. You can optionally specify aumgentations for the training using the `DatasetAugmentation` dataclass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import DatasetAugmentations\n",
    "from focoos.ports import DatasetSplitType\n",
    "\n",
    "auto_dataset = AutoDataset(dataset_name=ds_name, task=ds_task, layout=ds_layout)\n",
    "\n",
    "train_augs = DatasetAugmentations(\n",
    "    resolution=512,\n",
    "    color_augmentation=1.0,\n",
    "    horizontal_flip=0.5,\n",
    "    vertical_flip=0.0,\n",
    "    rotation=0.0,\n",
    "    aspect_ratio=0.0,\n",
    "    scale_ratio=0.0,\n",
    "    crop=True,\n",
    ")\n",
    "valid_augs = DatasetAugmentations(resolution=512)\n",
    "# Optionally, you can also get the default augmentations for the task\n",
    "# train_augs, valid_augs = get_default_by_task(task, 512)\n",
    "\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=valid_augs.get_augmentations(), split=DatasetSplitType.VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "Let's also visualize a few augmented inputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_dataset.preview())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÉ‚Äç‚ôÇÔ∏è Train the model\n",
    "The next step is to train the model. You can train the model by calling the train method. You need to give it the hyperparameters, encapsulated in the `TrainerArgs`, the datasets and see the magic happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.ports import TrainerArgs\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=f\"{model_name}_{auto_dataset.dataset_name}\",  # the name of the experiment\n",
    "    output_dir=\"./experiments\",  # the folder where the model is saved, DEFAULT  ~/FocoosAI/models\"\n",
    "    batch_size=16,  # how many images in each iteration\n",
    "    max_iters=500,  # how many iterations lasts the training\n",
    "    eval_period=100,  # period after we eval the model on the validation (in iterations)\n",
    "    learning_rate=0.0001,  # learning rate\n",
    "    weight_decay=0.0001,  # regularization strenght (set it properly to avoid under/over fitting)\n",
    "    sync_to_hub=False,\n",
    ")  # Use this to sync model info, weights and metrics on the platform\n",
    "\n",
    "# Let's go!\n",
    "model.train(args, train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test your model\n",
    "Let's visualize some prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from focoos.utils.vision import annotate_image\n",
    "\n",
    "index = random.randint(0, len(valid_dataset))\n",
    "\n",
    "print(\"Ground truth:\")\n",
    "display(valid_dataset.preview(index, use_augmentations=False))\n",
    "\n",
    "image = Image.open(valid_dataset[index][\"file_name\"])\n",
    "outputs = model(image)\n",
    "\n",
    "print(\"Prediction:\")\n",
    "annotate_image(image, outputs, task=model.task, classes=model.model_info.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì§ Export Model and optimize inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.ports import RuntimeType\n",
    "\n",
    "infer_model = model.export(runtime_type=RuntimeType.TORCHSCRIPT_32)\n",
    "\n",
    "infer_model.benchmark(iterations=10)\n",
    "detections = infer_model.infer(image, threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
