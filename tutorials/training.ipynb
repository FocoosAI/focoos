{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßëüèΩ‚Äçüç≥ How to Train a Computer Vision Model with Focoos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêç Setup Focoos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'focoos @ git+https://github.com/FocoosAI/focoos.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® Fine-tune a model in few steps\n",
    "\n",
    "This section covers the steps to create a model and train it using the focoos library. The following example demonstrates how to interact with the Focoos API to manage models, datasets, and training jobs.\n",
    "\n",
    "In this guide, we will perform the following steps:\n",
    "\n",
    "\n",
    "0. ‚òÅÔ∏è [Optional] Connect with Focoos Hub\n",
    "1. üéØ Select Pretrained Model\n",
    "2. üì¶ Load a dataset\n",
    "3. üèÉ‚Äç‚ôÇÔ∏è Train the model\n",
    "4. üß™ Test your model\n",
    "5. üì§ Export your model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è [Optional] Connect with FocoosHUB\n",
    "\n",
    "Focoos can be used without having an accont on the [Focoos Hub](app.focoos.ai). With it, you will unlock additional functionalities, as we will see below. If you have it, just connect to the HUB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from focoos import FocoosHUB\n",
    "\n",
    "FOCOOS_API_KEY = os.getenv(\n",
    "    \"FOCOOS_API_KEY\"\n",
    ")  # write here your API key os set env variable FOCOOS_API_KEY, will be used as default\n",
    "hub = FocoosHUB(api_key=FOCOOS_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ List Pretrained Focoos Models with ModelRegistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import ModelRegistry\n",
    "\n",
    "model_registry = ModelRegistry()\n",
    "\n",
    "for m in model_registry.list_models():\n",
    "    model_info = model_registry.get_model_info(m)\n",
    "    model_info.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model with ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import ModelManager\n",
    "\n",
    "model_name = \"fai-detr-l-obj365\"\n",
    "model = ModelManager.get(model_name)\n",
    "model.model_info.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Download datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public toy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import DATASETS_DIR, DatasetLayout, Task\n",
    "from focoos.hub.api_client import ApiClient\n",
    "\n",
    "ds_task = Task.DETECTION\n",
    "\n",
    "\n",
    "def get_dataset(task: Task):\n",
    "    if task == Task.SEMSEG:\n",
    "        ds_name = \"balloons-coco-sem.zip\"\n",
    "        layout = DatasetLayout.ROBOFLOW_SEG\n",
    "    elif task == Task.DETECTION:\n",
    "        ds_name = \"chess-coco-detection.zip\"\n",
    "        layout = DatasetLayout.ROBOFLOW_COCO\n",
    "    elif task == Task.INSTANCE_SEGMENTATION:\n",
    "        ds_name = \"fire-coco-instseg.zip\"\n",
    "        layout = DatasetLayout.ROBOFLOW_COCO\n",
    "    else:\n",
    "        raise ValueError(f\"Error: task {task} not supported\")\n",
    "    url = f\"https://public.focoos.ai/datasets/{ds_name}\"\n",
    "    api_client = ApiClient()\n",
    "    api_client.download_ext_file(url, DATASETS_DIR, skip_if_exists=True)\n",
    "    return ds_name, layout\n",
    "\n",
    "\n",
    "# Downlaod sample dataset\n",
    "ds_name, ds_layout = get_dataset(ds_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Datasets from focoos Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to download a dataset from the hub, you can use the hub to directly store it in your local environment.\n",
    "Check the reference of your dataset on the platform and use it in the following cell.\n",
    "In the next cell, we will download a dataset by reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_datasets = hub.list_remote_datasets()\n",
    "for dataset in hub_datasets:\n",
    "    print(dataset.ref, dataset.name, dataset.layout, dataset.task)\n",
    "\n",
    "\n",
    "ref = None  # place here the ref of the dataset you want to download\n",
    "if ref is not None:\n",
    "    dataset = hub.get_remote_dataset(ref)\n",
    "    dataset_path = dataset.download_data()\n",
    "    ds_name = dataset_path\n",
    "    ds_layout = dataset.layout\n",
    "    ds_task = dataset.task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoDataset and Augmentation\n",
    "Now that we downloaded the dataset, we can magically ü™Ñ instanciate the dataset using the `AutoDataset` as will be used in the training. You can optionally specify aumgentations for the training using the `DatasetAugmentation` dataclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import DatasetSplitType\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import DatasetAugmentations\n",
    "\n",
    "auto_dataset = AutoDataset(dataset_name=ds_name, task=ds_task, layout=ds_layout)\n",
    "\n",
    "train_augs = DatasetAugmentations(\n",
    "    resolution=512,\n",
    "    color_augmentation=1.0,\n",
    "    horizontal_flip=0.5,\n",
    "    vertical_flip=0.0,\n",
    "    rotation=0.0,\n",
    "    aspect_ratio=0.0,\n",
    "    scale_ratio=0.0,\n",
    "    crop=True,\n",
    ")\n",
    "valid_augs = DatasetAugmentations(resolution=512)\n",
    "# Optionally, you can also get the default augmentations for the task\n",
    "# train_augs, valid_augs = get_default_by_task(task, 512)\n",
    "\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=valid_augs.get_augmentations(), split=DatasetSplitType.VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize\n",
    "Let's also visualize a few augmented inputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_dataset.preview())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÉ‚Äç‚ôÇÔ∏è Train the model\n",
    "The next step is to train the model. You can train the model by calling the train method. You need to give it the hyperparameters, encapsulated in the `TrainerArgs`, the datasets and see the magic happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import TrainerArgs\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=f\"{model.name}_{train_dataset.name}\",  # the name of the experiment\n",
    "    output_dir=\"./experiments\",  # the folder where the model is saved, DEFAULT  ~/FocoosAI/models\"\n",
    "    batch_size=16,  # how many images in each iteration\n",
    "    max_iters=500,  # how many iterations lasts the training\n",
    "    eval_period=200,  # period after we eval the model on the validation (in iterations)\n",
    "    learning_rate=0.0001,  # learning rate\n",
    "    weight_decay=0.0001,  # regularization strenght (set it properly to avoid under/over fitting)\n",
    "    sync_to_hub=False,\n",
    ")  # Use this to sync model info, weights and metrics on the platform\n",
    "\n",
    "# Let's go!\n",
    "model.train(\n",
    "    args, train_dataset, valid_dataset, hub=None\n",
    ")  # Hub is optional, if not provided and sync_to_hub is True, will be created automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test your model\n",
    "Let's visualize some prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "index = random.randint(0, len(valid_dataset))\n",
    "\n",
    "print(\"Ground truth:\")\n",
    "display(valid_dataset.preview(index, use_augmentations=False))\n",
    "\n",
    "image = Image.open(valid_dataset[index][\"file_name\"])\n",
    "outputs = model.infer(image, annotate=True)\n",
    "\n",
    "print(\"Prediction:\")\n",
    "display(Image.fromarray(outputs.image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì§ Export Model and optimize inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos import RuntimeType\n",
    "\n",
    "infer_model = model.export(runtime_type=RuntimeType.TORCHSCRIPT_32)\n",
    "\n",
    "infer_model.benchmark(iterations=10)\n",
    "detections = infer_model.infer(image, threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
