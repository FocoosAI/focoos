{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_registry import ModelRegistry\n",
    "\n",
    "registry = ModelRegistry()\n",
    "print(registry.list_models())\n",
    "\n",
    "\n",
    "model_info = registry.get_model_info(\"fai-detr-l-obj365\")\n",
    "\n",
    "model_info.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.ports import DatasetLayout, DatasetSplitType, Task\n",
    "\n",
    "task = Task.DETECTION\n",
    "layout = DatasetLayout.ROBOFLOW_COCO\n",
    "auto_dataset = AutoDataset(dataset_name=\"aquarium\", task=task, layout=layout, datasets_dir=\"../datasets\")\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(task, 640, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_manager import ModelManager\n",
    "\n",
    "model = ModelManager.get(\"fai-detr-m-coco\", num_classes=train_dataset.dataset.metadata.num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with a dataset downloaded from HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.hub.focoos_hub import FocoosHUB\n",
    "from focoos.model_manager import ModelManager\n",
    "from focoos.ports import LOCAL_API_URL, DatasetLayout, DatasetSplitType, RuntimeType, Task, TrainerArgs\n",
    "\n",
    "hub = FocoosHUB(host_url=LOCAL_API_URL)\n",
    "my_datasets = hub.list_remote_datasets(include_shared=False)\n",
    "remote_dataset = hub.get_remote_dataset(\"a42e1149e257429d\")\n",
    "dataset_path = remote_dataset.download_data()\n",
    "auto_dataset = AutoDataset(dataset_name=dataset_path, task=remote_dataset.task, layout=remote_dataset.layout)\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(remote_dataset.task, 640, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "\n",
    "model = ModelManager.get(\"fai-detr-l-coco\")\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=f\"{remote_dataset.name}-{model.model_info.name}\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=500,\n",
    "    eval_period=50,\n",
    "    learning_rate=0.0008,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.02,\n",
    "    workers=16,\n",
    "    patience=1,\n",
    ")\n",
    "\n",
    "\n",
    "model.train(args, train_dataset, valid_dataset)\n",
    "infer = model.export(runtime_type=RuntimeType.TORCHSCRIPT_32)\n",
    "infer.benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.ports import TrainerArgs\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"aquarium2\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=300,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "model.test(args, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model for inference\n",
    "from PIL import Image\n",
    "\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.model_manager import ModelManager\n",
    "from focoos.ports import DatasetLayout, DatasetSplitType, Task, TrainerArgs\n",
    "\n",
    "task = Task.DETECTION\n",
    "layout = DatasetLayout.ROBOFLOW_COCO\n",
    "auto_dataset = AutoDataset(dataset_name=\"aquarium\", task=task, layout=layout)\n",
    "resolution = 640\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(task, resolution, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "\n",
    "model = ModelManager.get(\"fai-detr-m-coco\", num_classes=train_dataset.dataset.metadata.num_classes)\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"exp1\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=100,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "model.train(args, train_dataset, valid_dataset)\n",
    "\n",
    "image = Image.open(\"image.jpg\")\n",
    "\n",
    "outputs = model(image)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model for inference\n",
    "from PIL import Image\n",
    "\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.model_manager import ConfigManager, ModelManager\n",
    "from focoos.nn.backbone.resnet import ResnetConfig\n",
    "from focoos.ports import (\n",
    "    DatasetLayout,\n",
    "    DatasetSplitType,\n",
    "    ModelFamily,\n",
    "    ModelInfo,\n",
    "    Task,\n",
    "    TrainerArgs,\n",
    ")\n",
    "\n",
    "task = Task.CLASSIFICATION\n",
    "layout = DatasetLayout.CLS_FOLDER\n",
    "auto_dataset = AutoDataset(dataset_name=\"hymenoptera\", task=task, layout=layout)\n",
    "resolution = 224\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(task, resolution, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "\n",
    "# Create a configuration with a ResNet backbone\n",
    "cls_config = ConfigManager.from_dict(\n",
    "    ModelFamily.IMAGE_CLASSIFIER,\n",
    "    {\n",
    "        \"backbone_config\": dict(ResnetConfig(model_type=\"resnet\", depth=50, pretrained=True)),\n",
    "        \"num_classes\": valid_dataset.dataset.metadata.num_classes,\n",
    "        \"resolution\": resolution,\n",
    "        \"hidden_dim\": 512,\n",
    "        \"dropout_rate\": 0.2,\n",
    "    },\n",
    ")\n",
    "\n",
    "model_info = ModelInfo(\n",
    "    name=\"fai-cls-resnet50\",\n",
    "    description=\"ResNet50 model for classification\",\n",
    "    task=Task.CLASSIFICATION,\n",
    "    classes=[\"cat\", \"dog\", \"bird\"],\n",
    "    im_size=224,\n",
    "    model_family=ModelFamily.IMAGE_CLASSIFIER,\n",
    "    config=cls_config,\n",
    ")\n",
    "# Create the model\n",
    "model = ModelManager.get(name=model_info.name, model_info=model_info)\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"footballxyz\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=50,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "model.train(args, train_dataset, valid_dataset)\n",
    "\n",
    "image = Image.open(\"image.jpg\")\n",
    "outputs = model(image)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.model_manager import ModelManager\n",
    "from focoos.ports import DatasetLayout, DatasetSplitType, Task, TrainerArgs\n",
    "\n",
    "task = Task.SEMSEG\n",
    "layout = DatasetLayout.ROBOFLOW_SEG\n",
    "auto_dataset = AutoDataset(dataset_name=\"pizza\", task=task, layout=layout)\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(task, 640, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "model = ModelManager.get(\"bisenetformer-m-ade\", num_classes=valid_dataset.dataset.metadata.num_classes)\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"footballxyz\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=50,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "model.train(args, train_dataset, valid_dataset)\n",
    "\n",
    "image = Image.open(\"image.jpg\")\n",
    "outputs = model(image)\n",
    "\n",
    "# print(outputs.logits.shape,outputs.masks.shape)\n",
    "for det in outputs[0].detections:\n",
    "    print(det.cls_id, det.conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.model_manager import ModelManager\n",
    "from focoos.ports import DatasetLayout, DatasetSplitType, Task, TrainerArgs\n",
    "\n",
    "task = Task.INSTANCE_SEGMENTATION\n",
    "layout = DatasetLayout.ROBOFLOW_COCO\n",
    "auto_dataset = AutoDataset(dataset_name=\"fruits\", task=task, layout=layout)\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(task, 640, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "model = ModelManager.get(\"fai-mf-s-coco-ins\", num_classes=valid_dataset.dataset.metadata.num_classes)\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=\"footballxyz\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=50,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    ")\n",
    "\n",
    "model.train(args, train_dataset, valid_dataset)\n",
    "\n",
    "image = Image.open(\"image.jpg\")\n",
    "outputs = model(image)\n",
    "\n",
    "# print(outputs.logits.shape,outputs.masks.shape)\n",
    "for det in outputs[0].detections:\n",
    "    print(det.cls_id, det.bbox, det.conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.utils.system import get_system_info\n",
    "\n",
    "get_system_info().pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_registry import ModelRegistry\n",
    "\n",
    "registry = ModelRegistry()\n",
    "print(registry.list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_manager import ModelManager\n",
    "\n",
    "model = ModelManager.get(\"fai-detr-l-obj365\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "from focoos.ports import Task\n",
    "from focoos.utils.vision import fai_detections_to_sv\n",
    "\n",
    "# Initialize annotation utilities\n",
    "label_annotator = sv.LabelAnnotator(text_padding=10, border_radius=10)\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "\n",
    "\n",
    "def annotate(im, model_info, detections):\n",
    "    detections = fai_detections_to_sv(detections, im.shape[:2])\n",
    "    if len(detections.xyxy) == 0:\n",
    "        print(\"No detections found, skipping annotation\")\n",
    "        return im\n",
    "    classes = model_info.classes\n",
    "    labels = [\n",
    "        f\"{classes[int(class_id)] if classes is not None else str(class_id)}: {confid * 100:.0f}%\"\n",
    "        for class_id, confid in zip(detections.class_id, detections.confidence)  # type: ignore\n",
    "    ]\n",
    "    if model_info.task == Task.DETECTION:\n",
    "        annotated_im = box_annotator.annotate(scene=im.copy(), detections=detections)\n",
    "\n",
    "        annotated_im = label_annotator.annotate(scene=annotated_im, detections=detections, labels=labels)\n",
    "    elif model_info.task in [\n",
    "        Task.SEMSEG,\n",
    "        Task.INSTANCE_SEGMENTATION,\n",
    "    ]:\n",
    "        annotated_im = mask_annotator.annotate(scene=im.copy(), detections=detections)\n",
    "\n",
    "    return Image.fromarray(annotated_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison table of the benchmarking metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "\n",
    "from focoos.model_manager import ModelManager\n",
    "from focoos.model_registry import ModelRegistry\n",
    "from focoos.ports import RuntimeType\n",
    "\n",
    "registry = ModelRegistry()\n",
    "\n",
    "image = Image.open(\"image.jpg\")\n",
    "\n",
    "model_name = \"fai-detr-s-coco\"\n",
    "# model_name = \"fai-mf-m-coco-ins\"\n",
    "# model_name = \"fai-mf-m-ade\"\n",
    "# model_name = \"bisenetformer-m-ade\"\n",
    "\n",
    "model = ModelManager.get(model_name)\n",
    "\n",
    "metrics_torch = model.benchmark(iterations=50, size=640)\n",
    "metrics_torch_inner = model.model.benchmark(iterations=50, size=640)\n",
    "\n",
    "runtime_type = RuntimeType.TORCHSCRIPT_32\n",
    "infer = model.export(runtime_type=runtime_type, overwrite=True)\n",
    "metrics_trt = infer.benchmark(iterations=50, size=640)\n",
    "metrics_inner_ts = infer.runtime.benchmark(iterations=50, size=640)\n",
    "\n",
    "runtime_type = RuntimeType.ONNX_CUDA32\n",
    "infer = model.export(runtime_type=runtime_type, overwrite=True)\n",
    "metrics_onnx = infer.benchmark(iterations=50, size=640)\n",
    "metrics_inner_onnx = infer.runtime.benchmark(iterations=50, size=640)\n",
    "\n",
    "\n",
    "# Create data for the table\n",
    "headers = [\"Runtime\", \"FPS\", \"Mean Latency (ms)\", \"Std Deviation (ms)\"]\n",
    "table_data = [\n",
    "    [\"PyTorch\", metrics_torch.fps, metrics_torch.mean, metrics_torch.std],\n",
    "    [\"TorchScript\", metrics_trt.fps, metrics_trt.mean, metrics_trt.std],\n",
    "    [\"ONNX CUDA\", metrics_onnx.fps, metrics_onnx.mean, metrics_onnx.std],\n",
    "    [\"PyTorch Model\", metrics_torch_inner.fps, metrics_torch_inner.mean, metrics_torch_inner.std],\n",
    "    [\"TorchScript Model\", metrics_inner_ts.fps, metrics_inner_ts.mean, metrics_inner_ts.std],\n",
    "    [\"ONNX CUDA Model\", metrics_inner_onnx.fps, metrics_inner_onnx.mean, metrics_inner_onnx.std],\n",
    "]\n",
    "\n",
    "# Display the table using tabulate\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Optionally, create a bar chart to visualize FPS comparison\n",
    "runtimes = [row[0] for row in table_data]\n",
    "fps_values = [row[1] for row in table_data]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(runtimes, fps_values)\n",
    "plt.title(\"FPS Comparison Across Different Runtimes\")\n",
    "plt.xlabel(\"Runtime\")\n",
    "plt.ylabel(\"Frames Per Second (FPS)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training sync to HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison table of the benchmarking metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "\n",
    "from focoos.data.auto_dataset import AutoDataset\n",
    "from focoos.data.default_aug import get_default_by_task\n",
    "from focoos.hub import FocoosHUB\n",
    "from focoos.model_manager import ModelManager\n",
    "from focoos.model_registry import ModelRegistry\n",
    "from focoos.ports import LOCAL_API_URL, DatasetLayout, DatasetSplitType, RuntimeType, Task, TrainerArgs\n",
    "\n",
    "hub = FocoosHUB(host_url=LOCAL_API_URL)\n",
    "# my_datasets = hub.list_remote_datasets(include_shared=False)\n",
    "# remote_dataset = hub.get_remote_dataset(my_datasets[6].ref)\n",
    "# dataset_path = remote_dataset.download_data()\n",
    "\n",
    "\n",
    "auto_dataset = AutoDataset(dataset_name=\"Carrera_go_red_grey\", task=Task.DETECTION, layout=DatasetLayout.ROBOFLOW_COCO)\n",
    "\n",
    "train_augs, val_augs = get_default_by_task(Task.DETECTION, 640, advanced=False)\n",
    "train_dataset = auto_dataset.get_split(augs=train_augs.get_augmentations(), split=DatasetSplitType.TRAIN)\n",
    "valid_dataset = auto_dataset.get_split(augs=val_augs.get_augmentations(), split=DatasetSplitType.VAL)\n",
    "\n",
    "model = ModelManager.get(\"fai-detr-l-obj365\")\n",
    "\n",
    "args = TrainerArgs(\n",
    "    run_name=f\"{auto_dataset.name}-{model.model_info.name}-6\",\n",
    "    output_dir=\"./experiments\",\n",
    "    amp_enabled=True,\n",
    "    batch_size=16,\n",
    "    max_iters=1000,\n",
    "    eval_period=100,\n",
    "    learning_rate=0.0001,\n",
    "    scheduler=\"MULTISTEP\",\n",
    "    weight_decay=0.0001,\n",
    "    workers=16,\n",
    "    sync_to_hub=True,\n",
    ")\n",
    "\n",
    "\n",
    "model.train(args, train_dataset, valid_dataset, hub)\n",
    "model.export(runtime_type=RuntimeType.TORCHSCRIPT_32, overwrite=True)\n",
    "# infer = model.export(runtime_type=RuntimeType.TORCHSCRIPT_32, overwrite=True)\n",
    "# infer.benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_manager import ModelManager\n",
    "from focoos.ports import RuntimeType\n",
    "\n",
    "model = ModelManager.get(\"fai-detr-l-obj365\")\n",
    "model.export(runtime_type=RuntimeType.TORCHSCRIPT_32, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.utils.metrics import parse_metrics\n",
    "\n",
    "metrics = parse_metrics(\"/home/ubuntu/focoos/notebooks/experiments/carrera-fai-detr-m-coco/metrics.json\")\n",
    "print(metrics.iterations)\n",
    "print(metrics.valid_metrics)\n",
    "print(metrics.train_metrics)\n",
    "print(metrics.infer_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.model_manager import ModelManager\n",
    "from focoos.ports import RuntimeType\n",
    "\n",
    "models_dir = \"/home/ubuntu/focoos/notebooks/experiments\"\n",
    "model_name = \"haloaimbot\"\n",
    "\n",
    "model = ModelManager.get(model_name, models_dir=models_dir)\n",
    "infer = model.export(\n",
    "    runtime_type=RuntimeType.TORCHSCRIPT_32,\n",
    "    overwrite=True,\n",
    "    out_dir=f\"{models_dir}/{model_name}\",\n",
    ")\n",
    "infer.benchmark()\n",
    "infer.infer(\"./image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from focoos.infer.infer_model import InferModel\n",
    "from focoos.ports import ModelInfo, RuntimeType\n",
    "\n",
    "model_dir = \"/home/ubuntu/FocoosAI/models/fai-detr-l-obj365\"\n",
    "model_dir = \"/home/ubuntu/focoos/notebooks/experiments/Carrera_go_red_grey-fai-detr-l-obj365-6\"\n",
    "model_dir = \"/home/ubuntu/focoos/notebooks/experiments/haloaimbot\"\n",
    "model_info = ModelInfo.from_json(f\"{model_dir}/model_info.json\")\n",
    "print(model_info.config)\n",
    "infer = InferModel(model_dir=model_dir, model_info=model_info, runtime_type=RuntimeType.TORCHSCRIPT_32)\n",
    "infer.infer(\"./image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
